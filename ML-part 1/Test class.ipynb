{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Naive_bayes import NaiveBayes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.spatial import distance \n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from tqdm import trange\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import math as mt\n",
    "import time\n",
    "from numpy.linalg import inv, det\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfeat = pd.read_csv(\"mfeat/mfeat-fac\", delimiter=\"\\0\", sep=\"\\0\", header=None )\n",
    "mfeatFou = pd.read_csv(\"mfeat/mfeat-fou\", delimiter=\"\\0\", sep=\"\\0\", header=None )\n",
    "mfeatka = pd.read_csv(\"mfeat/mfeat-kar\", delimiter=\"\\0\", sep=\"\\0\", header=None )\n",
    "y = pd.read_csv(\"results/fuzzy_crisp_partition_572953998.csv\",sep=\"\\n\", header=None)\n",
    "y = y.values\n",
    "y  = [y[i][0] for i in range(len(y))]\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retirando os espaços. Transformando da elemento em uma lista com valores númericos, Atribuindo isso a uma \n",
    "# lista com tudo processado e normaliza\n",
    "def preprocessing(data):\n",
    "    new_data = []\n",
    "    for ex in data:\n",
    "        ex = ex[0].split(\" \")\n",
    "        exemplos1 = []\n",
    "        for element in ex:\n",
    "            if element != \"\":\n",
    "                exemplos1.append(element)\n",
    "        new_data.append(exemplos1) \n",
    "    \n",
    "    ## Normaliza\n",
    "  \n",
    "    new_data = np.array(new_data).astype(float)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(new_data)\n",
    "    new_data = scaler.transform(new_data)\n",
    "    return new_data\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfeat =  preprocessing(mfeat.values)\n",
    "mfeatFou =  preprocessing(mfeatFou.values)\n",
    "mfeatKa =  preprocessing(mfeatka.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/30 [01:04<31:06, 64.35s/it]\u001b[A\n",
      "  7%|▋         | 2/30 [02:18<31:21, 67.18s/it]\u001b[A\n",
      " 10%|█         | 3/30 [03:27<30:27, 67.70s/it]\u001b[A\n",
      " 13%|█▎        | 4/30 [04:35<29:24, 67.86s/it]\u001b[A\n",
      " 17%|█▋        | 5/30 [06:04<30:53, 74.14s/it]\u001b[A\n",
      " 20%|██        | 6/30 [07:23<30:14, 75.59s/it]\u001b[A\n",
      " 23%|██▎       | 7/30 [08:37<28:53, 75.37s/it]\u001b[A\n",
      " 27%|██▋       | 8/30 [09:53<27:41, 75.52s/it]\u001b[A\n",
      " 30%|███       | 9/30 [11:05<26:01, 74.36s/it]\u001b[A\n",
      " 33%|███▎      | 10/30 [12:21<24:55, 74.76s/it]\u001b[A\n",
      " 37%|███▋      | 11/30 [13:29<23:06, 72.99s/it]\u001b[A\n",
      " 40%|████      | 12/30 [14:41<21:47, 72.62s/it]\u001b[A\n",
      " 43%|████▎     | 13/30 [15:55<20:39, 72.89s/it]\u001b[A\n",
      " 47%|████▋     | 14/30 [17:20<20:25, 76.58s/it]\u001b[A\n",
      " 50%|█████     | 15/30 [18:40<19:23, 77.60s/it]\u001b[A\n",
      " 53%|█████▎    | 16/30 [20:00<18:16, 78.32s/it]\u001b[A\n",
      " 57%|█████▋    | 17/30 [21:20<17:05, 78.85s/it]\u001b[A\n",
      " 60%|██████    | 18/30 [22:32<15:21, 76.77s/it]\u001b[A\n",
      " 63%|██████▎   | 19/30 [23:45<13:50, 75.54s/it]\u001b[A\n",
      " 67%|██████▋   | 20/30 [25:00<12:34, 75.47s/it]\u001b[A\n",
      " 70%|███████   | 21/30 [26:15<11:19, 75.50s/it]\u001b[A\n",
      " 73%|███████▎  | 22/30 [27:38<10:20, 77.62s/it]\u001b[A\n",
      " 77%|███████▋  | 23/30 [28:47<08:45, 75.11s/it]\u001b[A\n",
      " 80%|████████  | 24/30 [30:02<07:29, 74.85s/it]\u001b[A\n",
      " 83%|████████▎ | 25/30 [31:15<06:12, 74.45s/it]\u001b[A\n",
      " 87%|████████▋ | 26/30 [32:55<05:28, 82.25s/it]\u001b[A\n",
      " 90%|█████████ | 27/30 [34:29<04:16, 85.63s/it]\u001b[A\n",
      " 93%|█████████▎| 28/30 [36:02<02:55, 87.83s/it]\u001b[A\n",
      " 97%|█████████▋| 29/30 [37:18<01:24, 84.23s/it]\u001b[A\n",
      "100%|██████████| 30/30 [38:30<00:00, 80.64s/it]\u001b[A\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "\n",
    "list_acc_n = []\n",
    "count = 0\n",
    "\n",
    "\n",
    "for i in trange(0, 30):\n",
    "    acc_fold = []\n",
    "    for train_index, test_index in kf.split(np.array((mfeat))):\n",
    "       \n",
    "        X_trains = []\n",
    "        y_train_views = []\n",
    "        X_tests = []\n",
    "    \n",
    "        X_train_view1, X_test_view1 = mfeat[train_index], mfeat[test_index]\n",
    "        y_train_view1, y_test_view1 = y[train_index], y[test_index]\n",
    "      \n",
    "       \n",
    "       \n",
    "        X_train_view2, X_test_view2 = mfeatFou[train_index], mfeatFou[test_index]\n",
    "        y_train_view2, y_test_view2 = y[train_index], y[test_index]\n",
    "       \n",
    "   \n",
    "\n",
    "        X_train_view3, X_test_view3 = mfeatKa[train_index], mfeatKa[test_index]\n",
    "        y_train_view3, y_test_view3 = y[train_index], y[test_index]\n",
    "        \n",
    "  \n",
    "        \n",
    "        ##Values   \n",
    "        X_trains = [X_train_view1, X_train_view2, X_train_view3]\n",
    "        y_train_views = [y_train_view1, y_train_view2, y_train_view3]\n",
    "        X_tests = [X_test_view1, X_test_view2, X_test_view3]\n",
    "        nb = NaiveBayes()\n",
    "        \n",
    "        nb.fit(X_trains, y_train_views)\n",
    "        \n",
    "        y_pred = nb.predict(X_tests=X_tests);\n",
    "        \n",
    "        acc_fold = accuracy_score(y_test_view1, y_pred)\n",
    "        \n",
    "    list_acc_n.append(np.mean(acc_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_naive = pd.DataFrame(list_acc_n, columns=['acc'])\n",
    "acc_naive_csv = acc_naive.to_csv()\n",
    "arq = open(\"results/accuracy_naive\", \"w\")\n",
    "arq.write(acc_naive_csv)\n",
    "arq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6664999999999998"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.mean(list_acc_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação do KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from knn import KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = KNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_mfeat, X_test_mfeat, y_train_mfeat, y_test_mfeat =  train_test_split(mfeat,y, test_size=0.10, random_state=42)\n",
    "X_train_mfeatFou, X_test_mfeatFou, y_train_mfeatFou, y_test_mfeatFou =  train_test_split(mfeatFou,y, test_size=0.10, random_state=42)\n",
    "X_train_mfeatKa, X_test_mfeatKa, y_train_mfeatKa, y_test_mfeatKa =  train_test_split(mfeatKa,y, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trains = [X_train_mfeat, X_train_mfeatFou, X_train_mfeatKa]\n",
    "y_trains = [y_train_mfeat,y_train_mfeatFou, y_train_mfeatKa]\n",
    "tests = [X_test_mfeat, X_test_mfeatFou, X_test_mfeatKa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K:  3  ACC:  0.75\n",
      "K:  5  ACC:  0.75\n",
      "K:  7  ACC:  0.76\n",
      "K:  11  ACC:  0.745\n",
      "K:  13  ACC:  0.74\n"
     ]
    }
   ],
   "source": [
    "ks = [3,5,7, 11, 13]\n",
    "for k in ks:\n",
    "    model_knn = KNN()\n",
    "    model_knn.fit(X_trains=trains, y_trains=y_trains, k=k)\n",
    "    y =model_knn.predict(X_tests=tests)   \n",
    "    print(\"K: \", k, \" ACC: \", accuracy_score(y_test_mfeatFou, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/30 [02:51<1:22:56, 171.61s/it]\u001b[A\n",
      "  7%|▋         | 2/30 [05:42<1:19:54, 171.24s/it]\u001b[A\n",
      " 10%|█         | 3/30 [08:31<1:16:50, 170.77s/it]\u001b[A\n",
      " 13%|█▎        | 4/30 [11:21<1:13:56, 170.63s/it]\u001b[A\n",
      " 17%|█▋        | 5/30 [14:12<1:11:01, 170.45s/it]\u001b[A\n",
      " 20%|██        | 6/30 [17:01<1:08:00, 170.03s/it]\u001b[A\n",
      " 23%|██▎       | 7/30 [19:51<1:05:15, 170.24s/it]\u001b[A\n",
      " 27%|██▋       | 8/30 [22:41<1:02:20, 170.03s/it]\u001b[A\n",
      " 30%|███       | 9/30 [25:30<59:27, 169.90s/it]  \u001b[A\n",
      " 33%|███▎      | 10/30 [28:21<56:39, 170.00s/it]\u001b[A\n",
      " 37%|███▋      | 11/30 [31:11<53:51, 170.08s/it]\u001b[A\n",
      " 40%|████      | 12/30 [34:01<51:01, 170.11s/it]\u001b[A\n",
      " 43%|████▎     | 13/30 [36:52<48:14, 170.28s/it]\u001b[A\n",
      " 47%|████▋     | 14/30 [39:42<45:23, 170.19s/it]\u001b[A\n",
      " 50%|█████     | 15/30 [42:32<42:32, 170.15s/it]\u001b[A\n",
      " 53%|█████▎    | 16/30 [45:21<39:39, 169.97s/it]\u001b[A\n",
      " 57%|█████▋    | 17/30 [48:12<36:51, 170.08s/it]\u001b[A\n",
      " 60%|██████    | 18/30 [51:01<33:59, 169.97s/it]\u001b[A\n",
      " 63%|██████▎   | 19/30 [53:52<31:11, 170.15s/it]\u001b[A\n",
      " 67%|██████▋   | 20/30 [56:41<28:19, 169.95s/it]\u001b[A\n",
      " 70%|███████   | 21/30 [59:31<25:28, 169.86s/it]\u001b[A\n",
      " 73%|███████▎  | 22/30 [1:02:21<22:37, 169.73s/it]\u001b[A\n",
      " 77%|███████▋  | 23/30 [1:05:11<19:48, 169.80s/it]\u001b[A\n",
      " 80%|████████  | 24/30 [1:08:00<16:57, 169.61s/it]\u001b[A\n",
      " 83%|████████▎ | 25/30 [1:10:49<14:07, 169.59s/it]\u001b[A\n",
      " 87%|████████▋ | 26/30 [1:13:39<11:18, 169.53s/it]\u001b[A\n",
      " 90%|█████████ | 27/30 [1:16:28<08:28, 169.56s/it]\u001b[A\n",
      " 93%|█████████▎| 28/30 [1:19:18<05:39, 169.66s/it]\u001b[A\n",
      " 97%|█████████▋| 29/30 [1:22:08<02:49, 169.61s/it]\u001b[A\n",
      "100%|██████████| 30/30 [1:24:58<00:00, 169.73s/it]\u001b[A\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "list_acc_knn = []\n",
    "\n",
    "\n",
    "for i in trange(0, 30):\n",
    "    acc_fold = []\n",
    "    for train_index, test_index in kf.split(np.array(X_train_mfeat)):\n",
    "       \n",
    "        X_trains = []\n",
    "        y_train_views = []\n",
    "        X_tests = []\n",
    "    \n",
    "        X_train_view1, X_test_view1 = mfeat[train_index], mfeat[test_index]\n",
    "        y_train_view1, y_test_view1 = y[train_index], y[test_index]\n",
    "      \n",
    "       \n",
    "       \n",
    "        X_train_view2, X_test_view2 = mfeatFou[train_index], mfeatFou[test_index]\n",
    "        y_train_view2, y_test_view2 = y[train_index], y[test_index]\n",
    "       \n",
    "   \n",
    "\n",
    "        X_train_view3, X_test_view3 = mfeatKa[train_index], mfeatKa[test_index]\n",
    "        y_train_view3, y_test_view3 = y[train_index], y[test_index]\n",
    "        \n",
    "  \n",
    "        \n",
    "        ##Values   \n",
    "        X_trains = [X_train_view1, X_train_view2, X_train_view3]\n",
    "        y_trains = [y_train_view1, y_train_view2, y_train_view3]\n",
    "        X_tests = [X_test_view1, X_test_view2, X_test_view3]\n",
    "        k = KNN()\n",
    "        \n",
    "        k.fit(X_trains=X_trains, y_trains=y_trains, k=7)\n",
    "        \n",
    "        y_pred = k.predict(X_tests=X_tests);\n",
    "        \n",
    "        acc_fold = accuracy_score(y_test_view1, y_pred)\n",
    "        \n",
    "    list_acc_knn.append(np.mean(acc_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.744"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.mean(list_acc_knn), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_knn = pd.DataFrame(list_acc_knn, columns=['acc'])\n",
    "acc_knn_csv = acc_knn.to_csv()\n",
    "arq = open(\"results/accuracy_knn\", \"w\")\n",
    "arq.write(acc_knn_csv)\n",
    "arq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_naive = pd.read_csv(\"results/accuracy_naive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_naive = acc_naive['acc'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = wilcoxon(acc_naive, list_acc_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.pvalue < 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
